#!/usr/bin/env python3
"""
ç®€å•çš„é¢‘åŸŸæ‰©æ•£è¡¥å…¨æµ‹è¯•è„šæœ¬
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
import sys
sys.path.append('src')

from fdiff.utils.imputation import FrequencyDomainImputer, evaluate_imputation_performance
from fdiff.utils.fourier import dft, idft
from fdiff.schedulers.sde import VEScheduler
from fdiff.models.score_models import ScoreModule


def create_synthetic_data(batch_size=8, max_len=100, n_channels=1):
    """åˆ›å»ºåˆæˆæ—¶é—´åºåˆ—æ•°æ®ç”¨äºæµ‹è¯•"""
    t = torch.linspace(0, 4*np.pi, max_len)
    
    # åˆ›å»ºåŒ…å«å¤šä¸ªé¢‘ç‡åˆ†é‡çš„ä¿¡å·
    signals = []
    for i in range(batch_size):
        # åŸºç¡€æ­£å¼¦æ³¢
        signal = torch.sin(t + i * 0.1)
        # æ·»åŠ é«˜é¢‘åˆ†é‡
        signal += 0.3 * torch.sin(3 * t + i * 0.2)
        # æ·»åŠ ä½é¢‘è¶‹åŠ¿
        signal += 0.2 * torch.sin(0.5 * t + i * 0.3)
        # æ·»åŠ å™ªå£°
        signal += 0.1 * torch.randn_like(t)
        
        signals.append(signal.unsqueeze(-1))  # æ·»åŠ é€šé“ç»´åº¦
    
    X = torch.stack(signals, dim=0)
    return X


def create_mock_score_model(max_len, n_channels):
    """åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„åˆ†æ•°æ¨¡å‹ç”¨äºæµ‹è¯•"""
    
    class MockScoreModel:
        def __init__(self, max_len, n_channels):
            self.max_len = max_len
            self.n_channels = n_channels
            self.device = torch.device("cpu")
            
            # åˆ›å»ºå™ªå£°è°ƒåº¦å™¨
            self.noise_scheduler = VEScheduler(
                sigma_min=0.01,
                sigma_max=50.0,
                fourier_noise_scaling=True
            )
            self.noise_scheduler.set_noise_scaling(max_len)
            
        def eval(self):
            pass
            
        def to(self, device):
            self.device = device
            return self
            
        def __call__(self, batch):
            # ç®€å•çš„æ¨¡æ‹Ÿåˆ†æ•°å‡½æ•°ï¼šè¿”å›è¾“å…¥çš„è´Ÿå€¼ï¼ˆç®€å•çš„å»å™ªï¼‰
            X = batch.X
            # æ·»åŠ ä¸€äº›éšæœºæ€§æ¥æ¨¡æ‹ŸçœŸå®çš„åˆ†æ•°å‡½æ•°
            score = -0.1 * X + 0.05 * torch.randn_like(X)
            return score
    
    return MockScoreModel(max_len, n_channels)


def test_missing_mask_creation():
    """æµ‹è¯•ç¼ºå¤±å€¼æ©ç åˆ›å»º"""
    print("=== æµ‹è¯•ç¼ºå¤±å€¼æ©ç åˆ›å»º ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    X = create_synthetic_data(batch_size=2, max_len=50, n_channels=2)
    print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {X.shape}")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹
    mock_model = create_mock_score_model(X.shape[1], X.shape[2])
    imputer = FrequencyDomainImputer(mock_model)
    
    # æµ‹è¯•ä¸åŒçš„ç¼ºå¤±æ¨¡å¼
    patterns = ["random", "block", "channel"]
    missing_rate = 0.3
    
    for pattern in patterns:
        mask = imputer.create_missing_mask(X, missing_rate, pattern)
        actual_missing_rate = 1 - mask.float().mean().item()
        
        print(f"{pattern.capitalize()} æ¨¡å¼:")
        print(f"  ç›®æ ‡ç¼ºå¤±ç‡: {missing_rate:.1%}")
        print(f"  å®é™…ç¼ºå¤±ç‡: {actual_missing_rate:.1%}")
        print(f"  æ©ç å½¢çŠ¶: {mask.shape}")
        print()


def test_frequency_domain_operations():
    """æµ‹è¯•é¢‘åŸŸæ“ä½œ"""
    print("=== æµ‹è¯•é¢‘åŸŸæ“ä½œ ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    X = create_synthetic_data(batch_size=1, max_len=64, n_channels=1)
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {X.shape}")
    print(f"åŸå§‹æ•°æ®èŒƒå›´: [{X.min():.3f}, {X.max():.3f}]")
    
    # é¢‘åŸŸå˜æ¢
    X_freq = dft(X)
    print(f"é¢‘åŸŸæ•°æ®å½¢çŠ¶: {X_freq.shape}")
    print(f"é¢‘åŸŸæ•°æ®èŒƒå›´: [{X_freq.min():.3f}, {X_freq.max():.3f}]")
    
    # é€†å˜æ¢
    X_reconstructed = idft(X_freq)
    print(f"é‡æ„æ•°æ®å½¢çŠ¶: {X_reconstructed.shape}")
    print(f"é‡æ„æ•°æ®èŒƒå›´: [{X_reconstructed.min():.3f}, {X_reconstructed.max():.3f}]")
    
    # æ£€æŸ¥é‡æ„è¯¯å·®
    reconstruction_error = torch.mean((X - X_reconstructed) ** 2).item()
    print(f"é‡æ„è¯¯å·® (MSE): {reconstruction_error:.8f}")
    
    if reconstruction_error < 1e-6:
        print("âœ“ é¢‘åŸŸå˜æ¢æµ‹è¯•é€šè¿‡")
    else:
        print("âœ— é¢‘åŸŸå˜æ¢æµ‹è¯•å¤±è´¥")
    print()


def test_imputation_pipeline():
    """æµ‹è¯•å®Œæ•´çš„è¡¥å…¨æµç¨‹"""
    print("=== æµ‹è¯•è¡¥å…¨æµç¨‹ ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    X_true = create_synthetic_data(batch_size=2, max_len=64, n_channels=1)
    print(f"çœŸå®æ•°æ®å½¢çŠ¶: {X_true.shape}")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹
    mock_model = create_mock_score_model(X_true.shape[1], X_true.shape[2])
    
    # åˆ›å»ºè¡¥å…¨å™¨
    imputer = FrequencyDomainImputer(
        score_model=mock_model,
        diffusion_steps=10,  # ä½¿ç”¨è¾ƒå°‘æ­¥æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•
        noise_level=0.1,
        preserve_observed=True,
        max_iterations=1
    )
    
    # æ‰§è¡Œè¡¥å…¨
    print("æ‰§è¡Œè¡¥å…¨...")
    X_imputed, mask = imputer.impute(
        X_true,
        missing_rate=0.2,
        missing_pattern="random"
    )
    
    print(f"è¡¥å…¨æ•°æ®å½¢çŠ¶: {X_imputed.shape}")
    print(f"æ©ç å½¢çŠ¶: {mask.shape}")
    
    # è¯„ä¼°æ€§èƒ½
    metrics = evaluate_imputation_performance(X_true, X_imputed, mask)
    
    print("æ€§èƒ½æŒ‡æ ‡:")
    for key, value in metrics.items():
        print(f"  {key.upper()}: {value:.6f}")
    
    print("âœ“ è¡¥å…¨æµç¨‹æµ‹è¯•å®Œæˆ")
    print()


def test_visualization():
    """æµ‹è¯•å¯è§†åŒ–åŠŸèƒ½"""
    print("=== æµ‹è¯•å¯è§†åŒ– ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    X_true = create_synthetic_data(batch_size=1, max_len=100, n_channels=1)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹
    mock_model = create_mock_score_model(X_true.shape[1], X_true.shape[2])
    imputer = FrequencyDomainImputer(mock_model, diffusion_steps=5)
    
    # æ‰§è¡Œè¡¥å…¨
    X_imputed, mask = imputer.impute(
        X_true,
        missing_rate=0.3,
        missing_pattern="random"
    )
    
    # åˆ›å»ºå¯è§†åŒ–
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    
    # æå–æ•°æ®ç”¨äºç»˜å›¾
    x_true = X_true[0, :, 0].numpy()
    x_imputed = X_imputed[0, :, 0].numpy()
    mask_1d = mask[0, :, 0].numpy()
    
    # åˆ›å»ºå¸¦ç¼ºå¤±å€¼çš„ä¿¡å·
    x_missing = x_true.copy()
    x_missing[mask_1d == 0] = 0
    
    # å­å›¾1: æ—¶åŸŸæ¯”è¾ƒ
    time_steps = np.arange(len(x_true))
    axes[0, 0].plot(time_steps, x_true, 'b-', label='çœŸå®å€¼', alpha=0.8)
    axes[0, 0].plot(time_steps, x_missing, 'gray', label='å¸¦ç¼ºå¤±å€¼', alpha=0.6)
    axes[0, 0].plot(time_steps, x_imputed, 'r--', label='è¡¥å…¨å€¼', alpha=0.8)
    
    missing_indices = np.where(mask_1d == 0)[0]
    if len(missing_indices) > 0:
        axes[0, 0].scatter(missing_indices, x_imputed[missing_indices], 
                          c='red', s=20, label='è¡¥å…¨ç‚¹', zorder=5)
    
    axes[0, 0].set_title('æ—¶åŸŸè¡¥å…¨ç»“æœ')
    axes[0, 0].set_xlabel('æ—¶é—´æ­¥')
    axes[0, 0].set_ylabel('å€¼')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # å­å›¾2: è¯¯å·®åˆ†æ
    error = np.abs(x_true - x_imputed)
    axes[0, 1].plot(time_steps, error, 'g-', alpha=0.8)
    if len(missing_indices) > 0:
        axes[0, 1].scatter(missing_indices, error[missing_indices], 
                          c='red', s=20, zorder=5)
    axes[0, 1].set_title('ç»å¯¹è¯¯å·®')
    axes[0, 1].set_xlabel('æ—¶é—´æ­¥')
    axes[0, 1].set_ylabel('|çœŸå®å€¼ - è¡¥å…¨å€¼|')
    axes[0, 1].grid(True, alpha=0.3)
    
    # å­å›¾3: é¢‘åŸŸæ¯”è¾ƒ
    X_true_freq = dft(X_true).squeeze().numpy()
    X_imputed_freq = dft(X_imputed).squeeze().numpy()
    
    freq_bins = np.arange(len(X_true_freq))
    axes[1, 0].plot(freq_bins, X_true_freq[:, 0], 'b-', label='çœŸå®å€¼(é¢‘åŸŸ)', alpha=0.8)
    axes[1, 0].plot(freq_bins, X_imputed_freq[:, 0], 'r--', label='è¡¥å…¨å€¼(é¢‘åŸŸ)', alpha=0.8)
    axes[1, 0].set_title('é¢‘åŸŸæ¯”è¾ƒ')
    axes[1, 0].set_xlabel('é¢‘ç‡åˆ†é‡')
    axes[1, 0].set_ylabel('å¹…åº¦')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # å­å›¾4: ç¼ºå¤±æ¨¡å¼
    axes[1, 1].plot(time_steps, mask_1d, 'k-', linewidth=2)
    axes[1, 1].fill_between(time_steps, 0, mask_1d, alpha=0.3, color='blue', label='è§‚æµ‹å€¼')
    axes[1, 1].fill_between(time_steps, 0, 1-mask_1d, alpha=0.3, color='red', label='ç¼ºå¤±å€¼')
    axes[1, 1].set_title(f'ç¼ºå¤±æ¨¡å¼ (ç¼ºå¤±ç‡: {(1-mask_1d.mean()):.1%})')
    axes[1, 1].set_xlabel('æ—¶é—´æ­¥')
    axes[1, 1].set_ylabel('æ©ç å€¼')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    output_dir = Path("test_results")
    output_dir.mkdir(exist_ok=True)
    plt.savefig(output_dir / "imputation_test.png", dpi=150, bbox_inches='tight')
    print(f"å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {output_dir / 'imputation_test.png'}")
    
    # æ˜¾ç¤ºå›¾åƒï¼ˆå¦‚æœåœ¨äº¤äº’ç¯å¢ƒä¸­ï¼‰
    try:
        plt.show()
    except:
        pass
    
    plt.close()
    print("âœ“ å¯è§†åŒ–æµ‹è¯•å®Œæˆ")
    print()


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹é¢‘åŸŸæ‰©æ•£è¡¥å…¨æµ‹è¯•...\n")
    
    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
    torch.manual_seed(42)
    np.random.seed(42)
    
    try:
        # è¿è¡Œå„é¡¹æµ‹è¯•
        test_missing_mask_creation()
        test_frequency_domain_operations()
        test_imputation_pipeline()
        test_visualization()
        
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. è®­ç»ƒçœŸå®çš„é¢‘åŸŸæ‰©æ•£æ¨¡å‹:")
        print("   python cmd/train.py fourier_transform=true datamodule=ecg")
        print("2. ä½¿ç”¨çœŸå®æ¨¡å‹è¿›è¡Œè¡¥å…¨:")
        print("   python cmd/impute.py model_id=YOUR_MODEL_ID missing_rate=0.2")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 